{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QVpp6Xj8-xJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_3eVuJy9CcF"
      },
      "outputs": [],
      "source": [
        "!pip -q install geopandas libpysal esda splot mapclassify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5AUqJkci6ksh"
      },
      "outputs": [],
      "source": [
        "!pip install geopandas pyproj shapely fiona\n",
        "!pip install libpysal esda splot mapclassify\n",
        "!pip install matplotlib pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oveDpKWR9Rlr"
      },
      "source": [
        "# 1. Load the shapefiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv9WxPdE9NlO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_dir = \"your_data_path_here\"  # Update this to your actual data directory\n",
        "\n",
        "paths = {\n",
        "    \"original\": os.path.join(data_dir, \"original_points.shp\"),\n",
        "    \"donut\": os.path.join(data_dir, \"moved_points_donut.shp\"),\n",
        "    \"agdm\": os.path.join(data_dir, \"moved_points_agdm.shp\"),\n",
        "}\n",
        "\n",
        "gdfs = {k: gpd.read_file(v) for k, v in paths.items()}\n",
        "\n",
        "for name, gdf in gdfs.items():\n",
        "    print(name, \"rows =\", len(gdf), \"| CRS =\", gdf.crs)\n",
        "    print(\"columns:\", list(gdf.columns))\n",
        "    print(gdf.head(2), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXTHCH89bwf"
      },
      "source": [
        "# 2. Project data to meters (required for spatial distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALOW76Ko9lq2"
      },
      "outputs": [],
      "source": [
        "target_epsg = 25832\n",
        "\n",
        "for name in gdfs:\n",
        "    gdfs[name] = gdfs[name].to_crs(epsg=target_epsg)\n",
        "    gdfs[name][\"x\"] = gdfs[name].geometry.x\n",
        "    gdfs[name][\"y\"] = gdfs[name].geometry.y\n",
        "\n",
        "[gdfs[name].crs for name in gdfs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_adDyIjT9oGz"
      },
      "source": [
        "# 3. Plot: overlay of point locations (original vs masked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTVQvtyz9r4I"
      },
      "outputs": [],
      "source": [
        "out_dir = \"your_output_path_here\"  # Update this to your desired output directory\n",
        "fig_dir = os.path.join(out_dir, \"figures\")\n",
        "tab_dir = os.path.join(out_dir, \"tables\")\n",
        "\n",
        "os.makedirs(fig_dir, exist_ok=True)\n",
        "os.makedirs(tab_dir, exist_ok=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,7))\n",
        "gdfs[\"original\"].plot(ax=ax, markersize=1, alpha=0.4, label=\"original\")\n",
        "gdfs[\"donut\"].plot(ax=ax, markersize=1, alpha=0.4, label=\"donut\")\n",
        "gdfs[\"agdm\"].plot(ax=ax, markersize=1, alpha=0.4, label=\"agdm\")\n",
        "\n",
        "ax.set_title(\"Point locations: original vs Donut vs AGDM\")\n",
        "ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "\n",
        "overlay_path = os.path.join(fig_dir, \"points_overlay.png\")\n",
        "plt.savefig(overlay_path, dpi=250)\n",
        "plt.show()\n",
        "\n",
        "overlay_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_jl1vOu9uqK"
      },
      "source": [
        "# 4. Build spatial weights (k-nearest neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucTUTGjD92Vf"
      },
      "outputs": [],
      "source": [
        "from libpysal.weights import KNN\n",
        "\n",
        "k_main = 8\n",
        "\n",
        "def knn_weights(gdf, k=8):\n",
        "    coords = np.column_stack([gdf[\"x\"].to_numpy(), gdf[\"y\"].to_numpy()])\n",
        "    w = KNN.from_array(coords, k=k)\n",
        "    w.transform = \"R\"  # row-standardized\n",
        "    return w\n",
        "\n",
        "weights = {name: knn_weights(gdfs[name], k_main) for name in gdfs}\n",
        "\n",
        "# quick check\n",
        "print(\"n =\", weights[\"original\"].n)\n",
        "print(\"mean neighbors =\", np.mean(list(weights[\"original\"].cardinalities.values())))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iKaLj_L93mx"
      },
      "source": [
        "# 5. Global Moran’s I + Geary’s C (sleep_diso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9xqHNSg96vr"
      },
      "outputs": [],
      "source": [
        "from esda.moran import Moran\n",
        "from esda.geary import Geary\n",
        "\n",
        "def global_stats(gdf, w, col=\"sleep_diso\"):\n",
        "    y = np.asarray(gdf[col], dtype=float)\n",
        "    moran = Moran(y, w, permutations=999)\n",
        "    geary = Geary(y, w, permutations=999)\n",
        "    return {\n",
        "        \"moran_I\": moran.I,\n",
        "        \"moran_p\": moran.p_sim,\n",
        "        \"moran_z\": moran.z_sim,\n",
        "        \"geary_C\": geary.C,\n",
        "        \"geary_p\": geary.p_sim,\n",
        "        \"geary_z\": geary.z_sim,\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for ds in [\"original\", \"donut\", \"agdm\"]:\n",
        "    stats = global_stats(gdfs[ds], weights[ds], \"sleep_diso\")\n",
        "    rows.append({\"dataset\": ds, **stats})\n",
        "\n",
        "global_df = pd.DataFrame(rows)\n",
        "global_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa47NaOb9_co"
      },
      "outputs": [],
      "source": [
        "global_path = os.path.join(tab_dir, \"global_autocorrelation_sleep.csv\")\n",
        "global_df.to_csv(global_path, index=False)\n",
        "global_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D-rTLwh98hQ"
      },
      "source": [
        "# 6. Sensitivity analysis: Moran’s I for multiple k values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l4F0sPv-EZc"
      },
      "outputs": [],
      "source": [
        "ks = [6, 8, 10, 12]\n",
        "\n",
        "sens_rows = []\n",
        "for k in ks:\n",
        "    for ds in [\"original\", \"donut\", \"agdm\"]:\n",
        "        w = knn_weights(gdfs[ds], k=k)\n",
        "        y = np.asarray(gdfs[ds][\"sleep_diso\"], dtype=float)\n",
        "        m = Moran(y, w, permutations=999)\n",
        "        sens_rows.append({\n",
        "            \"dataset\": ds,\n",
        "            \"k\": k,\n",
        "            \"moran_I\": m.I,\n",
        "            \"p\": m.p_sim\n",
        "        })\n",
        "\n",
        "sens_df = pd.DataFrame(sens_rows)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots(figsize=(7,4))\n",
        "for ds in [\"original\", \"donut\", \"agdm\"]:\n",
        "    d = sens_df[sens_df[\"dataset\"] == ds].sort_values(\"k\")\n",
        "    ax.plot(d[\"k\"], d[\"moran_I\"], marker=\"o\", label=ds)\n",
        "\n",
        "ax.set_title(\"Sensitivity of Moran's I (sleep_diso) to k\")\n",
        "ax.set_xlabel(\"k nearest neighbors\")\n",
        "ax.set_ylabel(\"Moran's I\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "sens_plot_path = os.path.join(fig_dir, \"sensitivity_moran_sleep.png\")\n",
        "plt.savefig(sens_plot_path, dpi=250)\n",
        "plt.show()\n",
        "\n",
        "sens_plot_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbrABMS_-H8P"
      },
      "outputs": [],
      "source": [
        "sens_table_path = os.path.join(tab_dir, \"sensitivity_moran_sleep.csv\")\n",
        "sens_df.to_csv(sens_table_path, index=False)\n",
        "sens_table_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ikoYY7H-JFT"
      },
      "source": [
        "# 7. Local Moran (LISA) clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jo_oTJd-Nwh"
      },
      "outputs": [],
      "source": [
        "from esda.moran import Moran_Local\n",
        "\n",
        "def lisa_labels(local_moran, y, w):\n",
        "    z = (y - y.mean()) / y.std()\n",
        "    lag_z = w.sparse @ z\n",
        "    q = local_moran.q\n",
        "    sig = local_moran.p_sim < 0.05\n",
        "\n",
        "    labels = np.full(len(y), \"not significant\", dtype=object)\n",
        "    labels[(q == 1) & sig] = \"high-high\"\n",
        "    labels[(q == 2) & sig] = \"low-high\"\n",
        "    labels[(q == 3) & sig] = \"low-low\"\n",
        "    labels[(q == 4) & sig] = \"high-low\"\n",
        "    return labels\n",
        "\n",
        "lisa_results = {}\n",
        "\n",
        "for ds in [\"original\", \"donut\", \"agdm\"]:\n",
        "    gdf = gdfs[ds].copy()\n",
        "    y = np.asarray(gdf[\"sleep_diso\"], dtype=float)\n",
        "    w = weights[ds]\n",
        "\n",
        "    ml = Moran_Local(y, w, permutations=999)\n",
        "\n",
        "    gdf[\"lisa_I\"] = ml.Is\n",
        "    gdf[\"lisa_p\"] = ml.p_sim\n",
        "    gdf[\"lisa_cluster\"] = lisa_labels(ml, y, w)\n",
        "\n",
        "    lisa_results[ds] = gdf\n",
        "\n",
        "# check counts\n",
        "for ds in lisa_results:\n",
        "    print(ds)\n",
        "    print(lisa_results[ds][\"lisa_cluster\"].value_counts(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddr8Ahn9-Tzo"
      },
      "source": [
        "# 8. Plot LISA cluster maps (single slide figure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqPO7ZvU-WS4"
      },
      "outputs": [],
      "source": [
        "def plot_clusters(gdf, title, ax):\n",
        "    order = [\"high-high\", \"low-low\", \"high-low\", \"low-high\", \"not significant\"]\n",
        "    gdf = gdf.copy()\n",
        "    gdf[\"lisa_cluster\"] = pd.Categorical(gdf[\"lisa_cluster\"], categories=order, ordered=True)\n",
        "    gdf.plot(column=\"lisa_cluster\", ax=ax, markersize=3, legend=True)\n",
        "    ax.set_title(title)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
        "plot_clusters(lisa_results[\"original\"], \"Original\", axes[0])\n",
        "plot_clusters(lisa_results[\"donut\"], \"Donut masking\", axes[1])\n",
        "plot_clusters(lisa_results[\"agdm\"], \"AGDM masking\", axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "lisa_map_path = os.path.join(fig_dir, \"lisa_clusters_triptych.png\")\n",
        "plt.savefig(lisa_map_path, dpi=250)\n",
        "plt.show()\n",
        "\n",
        "lisa_map_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Ke5w2C-ZeY"
      },
      "source": [
        "# 9. Quantitative similarity (original vs donut / original vs AGDM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUlJ-gYN-cFW"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "def align_by_id(gdf_a, gdf_b):\n",
        "    a = gdf_a[[\"id\", \"lisa_I\", \"lisa_p\", \"lisa_cluster\"]].copy()\n",
        "    b = gdf_b[[\"id\", \"lisa_I\", \"lisa_p\", \"lisa_cluster\"]].copy()\n",
        "    return a.merge(b, on=\"id\", suffixes=(\"_orig\", \"_mask\"))\n",
        "\n",
        "def jaccard(a, b):\n",
        "    inter = np.logical_and(a, b).sum()\n",
        "    union = np.logical_or(a, b).sum()\n",
        "    return inter / union if union > 0 else np.nan\n",
        "\n",
        "orig = lisa_results[\"original\"]\n",
        "\n",
        "sim_rows = []\n",
        "for masked in [\"donut\", \"agdm\"]:\n",
        "    merged = align_by_id(orig, lisa_results[masked])\n",
        "\n",
        "    rho, _ = spearmanr(merged[\"lisa_I_orig\"], merged[\"lisa_I_mask\"])\n",
        "\n",
        "    sig_o = merged[\"lisa_p_orig\"] < 0.05\n",
        "    sig_m = merged[\"lisa_p_mask\"] < 0.05\n",
        "    jac_sig = jaccard(sig_o.to_numpy(), sig_m.to_numpy())\n",
        "\n",
        "    either = (sig_o | sig_m).to_numpy()\n",
        "    agree = (merged[\"lisa_cluster_orig\"] == merged[\"lisa_cluster_mask\"]).to_numpy()\n",
        "    cluster_agree = (agree & either).sum() / either.sum()\n",
        "\n",
        "    sim_rows.append({\n",
        "        \"masked_method\": masked,\n",
        "        \"spearman_local_I\": rho,\n",
        "        \"jaccard_significance\": jac_sig,\n",
        "        \"cluster_agreement_on_sig\": cluster_agree\n",
        "    })\n",
        "\n",
        "sim_df = pd.DataFrame(sim_rows)\n",
        "sim_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YeQrKL3-eXy"
      },
      "outputs": [],
      "source": [
        "sim_path = os.path.join(tab_dir, \"lisa_similarity_sleep.csv\")\n",
        "sim_df.to_csv(sim_path, index=False)\n",
        "sim_path\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
